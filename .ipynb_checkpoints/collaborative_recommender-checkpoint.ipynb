{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a6d3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import loading as ld\n",
    "import time\n",
    "import sys\n",
    "import load_data as lo\n",
    "import similarities as sm\n",
    "import pandas as pd\n",
    "class CollaborativeRecommender:\n",
    "    def __init__(self,urls = ['Books.csv','Users.csv','Book-Ratings.csv']):\n",
    "        self.urls = urls\n",
    "        self.sim = sm.Similarity()\n",
    "        self.dataset = lo.Load_data(self.urls)\n",
    "        self.data_frame = None\n",
    "        self.user_avg_rating_df = None\n",
    "        self.user_rating_counts_df  = None\n",
    "        self.user_rating_std_df = None\n",
    "        self.closest_n_similarity_df = None\n",
    "    def initate(self):\n",
    "        loading = ld.Loading()\n",
    "        print(\"## Collabarative Recomondation System by Asiri Thenuka Thenabadu : 31048197 ##\")\n",
    "        loading.start(text_start=\"Program Starting\")\n",
    "        time.sleep(1)\n",
    "        loading.stop(text_end= \"\")\n",
    "        loading.start(text_start=\"Loading Data Sets\")\n",
    "#         dataset = lo.Load_data(self.urls)\n",
    "        self.set_merged_dataset_df()\n",
    "#         self.data_frame = self.get_merged_dataset()\n",
    "        self.data_frame.head()\n",
    "        loading.stop(text_end= \"Data Set loaded Sucessfully\")\n",
    "#         loading.start(text_start=\"Loading Similarities\")\n",
    "#         sim = sm.Similarity()\n",
    "#         loading.stop(text_end= \"Similarities loaded Sucessfully !\")\n",
    "        loading.start(text_start=\"Please Insert Value to Begin \")\n",
    "        time.sleep(1)\n",
    "        loading.stop(text_end= \"\")\n",
    "        param1 = int(input(\"Target User Id : \"))\n",
    "        self.set_target_user(param1)\n",
    "        self.get_target_user()\n",
    "        \n",
    "        loading.start(text_start=\"Please Select Similarity matrix \")\n",
    "        time.sleep(1)\n",
    "        loading.stop(text_end= \"\")\n",
    "        awailable_modals = sm.awailable_modules()\n",
    "        for i,val in enumerate(awailable_modals):\n",
    "            print(\"\\r\"+str(i+1)+\".\"+val+\" \\n\")\n",
    "        sim_matrix = -99\n",
    "        while (int(sim_matrix) <= 0 or int(sim_matrix) > len(awailable_modals) or isinstance(sim_matrix, int) == False):\n",
    "            sim_matrix = int(input(\"Similarity Matrix Id : \"))\n",
    "            if(isinstance(sim_matrix, int)):\n",
    "                if(int(sim_matrix) < 0 and int(sim_matrix) > len(awailable_modals)):\n",
    "                    loading.start(text_start=\"Invalid Similarity Please select Correct Similarity \")\n",
    "                    time.sleep(2)\n",
    "                    loading.stop(text_end= \"\")\n",
    "            else:\n",
    "                loading.start(text_start=\"Invalid Similarity Please select Correct Similarity \")\n",
    "                time.sleep(2)\n",
    "                loading.stop(text_end= \"\")\n",
    "#                 sim_matrix = -99\n",
    "        else:\n",
    "            pass\n",
    "        print(\"You selected, \"+awailable_modals[sim_matrix-1])\n",
    "        cosest_n = self.get_closest_n_users(awailable_modals[sim_matrix-1])\n",
    "        print(cosest_n)\n",
    "#         self.get_closest_n_users(sim_matrix)\n",
    "        \n",
    "    def get_books_data(self):\n",
    "        return self.dataset.get_books_data()\n",
    "    def get_user_data(self):\n",
    "        return self.dataset.get_user_data()\n",
    "    def get_rating_data(self):\n",
    "        return self.dataset.get_rating_data()\n",
    "    def get_merged_dataset(self):\n",
    "        return self.dataset.merge_dataset()\n",
    "    def set_merged_dataset_df(self):\n",
    "        self.data_frame = self.get_merged_dataset()\n",
    "    def get_merged_dataset_df(self):\n",
    "        return self.data_frame\n",
    "    def plot_rating_distribution(self):\n",
    "        return self.data_frame['bookRating'].hist()\n",
    "    def get_users_avg_rating_DF():\n",
    "        self.user_avg_rating_df = self.data_frame.groupby('userID')[\"bookRating\"].mean().rename(\"user_avg_rating\").reset_index()\n",
    "    def get_user_rating_counts_DF():\n",
    "        self.user_rating_counts_df = self.data_frame.groupby('userID')[\"bookRating\"].count().rename(\"user_rating_counts\").reset_index()\n",
    "    def get_user_rating_std_DF():\n",
    "        self.user_rating_std_df = self.data_frame.groupby('userID')[\"bookRating\"].std(ddof=0).rename(\"user_rating_std\").reset_index()\n",
    "    def get_target_user(self):\n",
    "#         self.data_frame['userID'].count()\n",
    "        return self.data_frame.loc[self.data_frame['userID'] == self.target_user_id][['bookRating','ISBN']]\n",
    "    def set_target_user(self,target_user_id):\n",
    "        self.target_user_id = target_user_id\n",
    "        self.target_user_df = self.get_target_user()\n",
    "    def get_related_users(self):\n",
    "#         print(\"self.target_user_id =======>\",self.target_user_id)\n",
    "        temp_df = self.data_frame[self.data_frame['ISBN'].isin(self.target_user_df['ISBN'].tolist())]\n",
    "        return temp_df.loc[temp_df['userID'] != self.target_user_id]\n",
    "    def set_related_users(self):\n",
    "        self.related_users = self.get_related_users()\n",
    "#         print(\"set_related_users inside ===!! \",self.related_users)\n",
    "        self.related_users\n",
    "    def find_related_users(self):\n",
    "#         print(\"find_related_users func\")\n",
    "        #Getting related Users to the target user\n",
    "        self.set_related_users()\n",
    "#         print(\"set_related_users ===\",self.related_users)\n",
    "        # Grouping related Users\n",
    "        temp_group_by_df = self.related_users.groupby(['userID'])\n",
    "        #Sorting it so users with books most in common with the target user will have priority\n",
    "        self.related_users_orderd = sorted(temp_group_by_df,  key=lambda x: len(x[1]), reverse=True)\n",
    "    def set_closest_n_users(self):\n",
    "        simDict = {}\n",
    "        for name,group in self.related_users_orderd:\n",
    "            #Let's start by sorting the input and current user group so the values aren't mixed up later on\n",
    "            group = group.sort_values(by='ISBN')\n",
    "            targetsBooks = self.target_user_df.sort_values(by='ISBN')\n",
    "            #Get the rating scores for the books that they both have in common\n",
    "            temp_df = targetsBooks[targetsBooks['ISBN'].isin(group['ISBN'].tolist())]\n",
    "            tempRatingList = temp_df['bookRating'].tolist()\n",
    "            tempGroupList = group['bookRating'].tolist()\n",
    "            if(len(tempRatingList) > 2):\n",
    "                if(sum(tempRatingList) > 0 and sum(tempGroupList) > 0):\n",
    "                    similarity = sm.getSimilarity(sim = self.similarity_algo, target_r =tempRatingList , closest_r = tempGroupList)\n",
    "                    if (similarity != 'Undifined'):\n",
    "                        simDict[name] = similarity\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "        temp_sim_df = pd.DataFrame.from_dict(simDict, orient='index')\n",
    "        temp_sim_df.columns = ['similarityIndex']\n",
    "        temp_sim_df['userID'] = temp_sim_df.index\n",
    "        temp_sim_df.index = range(len(temp_sim_df))\n",
    "        self.closest_n_similarity_df = temp_sim_df.sort_values(by='similarityIndex', ascending=False)[0:50]\n",
    "    def get_closest_n_users(self,similarity_algo):\n",
    "#         print(\"here\")\n",
    "        self.similarity_algo = similarity_algo\n",
    "        self.find_related_users()\n",
    "        self.set_closest_n_users()\n",
    "        return self.closest_n_similarity_df\n",
    "        \n",
    "        \n",
    "# def main():\n",
    "#     initate()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdcd40f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    rec = CollaborativeRecommender()\n",
    "    rec.initate()\n",
    "#     276704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17dd5c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Collabarative Recomondation System by Asiri Thenuka Thenabadu : 31048197 ##\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KTarget User Id : 276704\n",
      "1.cosine_similarity rity matrix     \n",
      "\n",
      "2.euclidean_similarity \n",
      "\n",
      "3.hamming_distance_similarity \n",
      "\n",
      "4.minkowski_distance \n",
      "\n",
      "5.pearson_correlation \n",
      "\n",
      "6.pearson_correlation_scipy \n",
      "\n",
      "7.spearman_correlation_similarity \n",
      "\n",
      "8.squared_euclidean_similarity \n",
      "\n",
      "\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2KSimilarity Matrix Id : 6\n",
      "You selected, pearson_correlation_scipy\n",
      "   similarityIndex  userID\n",
      "9         1.000000  236959\n",
      "1         0.687500  185233\n",
      "5         0.609994  170513\n",
      "0         0.411706   11676\n",
      "8        -0.295745  236283\n",
      "6        -0.500000  225087\n",
      "7        -0.500000  235392\n",
      "2        -0.500000   13552\n",
      "3        -0.500000   16795\n",
      "4        -0.991241   43842\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a90cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import similarities as sm\n",
    "\n",
    "sim = sm.Similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9234ad9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cosine_similarity',\n",
       " 'euclidean_similarity',\n",
       " 'hamming_distance_similarity',\n",
       " 'minkowski_distance',\n",
       " 'pearson_correlation',\n",
       " 'pearson_correlation_scipy',\n",
       " 'spearman_correlation_similarity',\n",
       " 'squared_euclidean_similarity']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.awailable_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47cf318d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Collabarative Recomondation System by Asiri Thenuka Thenabadu : 31048197 ##\n",
      "Data Set loaded Sucessfully\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "# c.initate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "830504ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sim_matrix = -99\n",
    "# (sim_matrix < 0 or sim_matrix > 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12daa82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarityIndex</th>\n",
       "      <th>userID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>236959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>185233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.609994</td>\n",
       "      <td>170513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.411706</td>\n",
       "      <td>11676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.295745</td>\n",
       "      <td>236283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.500000</td>\n",
       "      <td>225087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.500000</td>\n",
       "      <td>235392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.500000</td>\n",
       "      <td>13552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.500000</td>\n",
       "      <td>16795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.991241</td>\n",
       "      <td>43842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   similarityIndex  userID\n",
       "9         1.000000  236959\n",
       "1         0.687500  185233\n",
       "5         0.609994  170513\n",
       "0         0.411706   11676\n",
       "8        -0.295745  236283\n",
       "6        -0.500000  225087\n",
       "7        -0.500000  235392\n",
       "2        -0.500000   13552\n",
       "3        -0.500000   16795\n",
       "4        -0.991241   43842"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = CollaborativeRecommender()\n",
    "sim.set_merged_dataset_df()\n",
    "sim.set_target_user(276704)\n",
    "sim.target_user_df\n",
    "ddf = sim.get_closest_n_users('pearson_correlation_scipy')\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5824b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d48f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
